"""
ReportingAgent - Generates structured reports with charts.

Implements Task 16: Structured Report Generation Agent
Implements Task P0-1: ReportingAgent

Responsibilities:
- Generate natural language insights with AI
- Create chart configurations for Recharts
- Produce metric cards with trends
- Include source citations for transparency
- Generate markdown tables for metric comparisons
- Provide period-over-period analysis with AI-powered insights
"""

import logging
from typing import Any, Dict, List
from datetime import datetime

from pydantic_ai import Agent, RunContext
from pydantic import BaseModel

from .base_agent import BaseAgent
from .schemas.results import (
    ReportResult,
    ChartDataPoint,
    MetricCard,
    SourceCitation,
)
from .schemas.charts import (
    LineChartConfig,
    BarChartConfig,
    PieChartConfig,
    AreaChartConfig,
)

logger = logging.getLogger(__name__)


class ReportInsight(BaseModel):
    """Structured insight generated by LLM."""
    insight: str
    confidence: float
    data_points: List[str]


class ReportSection(BaseModel):
    """Individual section of a report."""
    title: str
    content: str
    chart_config: Dict[str, Any] | None = None


class ReportingAgent(BaseAgent[ReportResult]):
    """
    Agent for generating structured reports.
    
    Implements Task P0-1: ReportingAgent
    
    Features:
    - Natural language insights generation
    - Chart configuration for Recharts
    - Metric cards with period-over-period comparison
    - Source citation for data provenance
    
    Contract:
        ReportingAgent.generate() → ReportResult(answer, charts, metrics)
    """
    
    def __init__(self, openai_api_key: str):
        """
        Initialize Reporting agent.
        
        Args:
            openai_api_key: OpenAI API key for LLM
        """
        super().__init__(
            name="reporting",
            model="openai:gpt-4o",
            retries=2,
            timeout_seconds=20,
        )
        self.api_key = openai_api_key
        
        # Create Pydantic-AI agent for report generation
        self._pydantic_agent = Agent(
            model=self.model,
            system_prompt=self.get_system_prompt(),
        )
    
    def get_system_prompt(self) -> str:
        """System prompt for Reporting agent."""
        return """You are an expert data analyst specializing in Google Analytics 4 reporting.

Your job is to:
1. Analyze GA4 metrics and trends
2. Generate clear, actionable insights
3. Create chart configurations for data visualization
4. Present findings in a structured format

Guidelines:
- Be concise and business-focused
- Highlight trends and anomalies
- Suggest actionable recommendations
- Use data visualization when helpful
- Always cite your sources

Output format:
- Natural language answer (2-3 paragraphs)
- Chart configurations (JSON for Recharts)
- Key metric cards with period-over-period changes
"""
    
    async def run_async(
        self,
        ctx: RunContext,
        query: str,
        ga4_data: Dict[str, Any],
        retrieved_context: List[str],
        citations: List[SourceCitation],
        tenant_id: str,
        **kwargs: Any
    ) -> ReportResult:
        """
        Generate structured report from GA4 data and context.
        
        Args:
            ctx: Run context
            query: User's original query
            ga4_data: Fresh GA4 data from DataFetcherAgent
            retrieved_context: Historical context from RagAgent
            citations: Source citations for provenance
            tenant_id: Tenant ID
            
        Returns:
            ReportResult with answer, charts, and metrics
        """
        try:
            logger.info(f"Generating report for query: {query}")
            
            # Extract metrics from GA4 data
            metrics_summary = self._extract_metrics(ga4_data)
            
            # Generate natural language answer
            answer = self._generate_answer(
                query=query,
                metrics=metrics_summary,
                context=retrieved_context,
            )
            
            # Create chart configurations
            charts = self._create_charts(ga4_data)
            
            # Create metric cards
            metric_cards = self._create_metric_cards(ga4_data)
            
            # Calculate confidence based on data quality
            confidence = self._calculate_confidence(
                ga4_data=ga4_data,
                context=retrieved_context,
            )
            
            logger.info(
                f"Report generated (confidence: {confidence:.2f})",
                extra={
                    "charts": len(charts),
                    "metrics": len(metric_cards),
                    "citations": len(citations)
                }
            )
            
            return ReportResult(
                answer=answer,
                charts=charts,
                metrics=metric_cards,
                citations=citations,
                confidence=confidence,
                tenant_id=tenant_id,
                query=query,
            )
            
        except Exception as e:
            logger.error(f"Report generation failed: {e}", exc_info=True)
            
            # Return fallback report
            return ReportResult(
                answer=f"I encountered an error generating the report: {str(e)}",
                charts=[],
                metrics=[],
                citations=citations,
                confidence=0.0,
                tenant_id=tenant_id,
                query=query,
            )
    
    def _extract_metrics(self, ga4_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract metrics summary from GA4 data."""
        rows = ga4_data.get("rows", [])
        
        if not rows:
            return {}
        
        # Extract metric values from first row (simplified)
        metrics = {}
        metric_headers = ga4_data.get("metricHeaders", [])
        
        for idx, header in enumerate(metric_headers):
            metric_name = header.get("name", f"metric_{idx}")
            if rows and idx < len(rows[0].get("metricValues", [])):
                metrics[metric_name] = rows[0]["metricValues"][idx].get("value", "0")
        
        return metrics
    
    def _generate_answer(
        self,
        query: str,
        metrics: Dict[str, Any],
        context: List[str],
    ) -> str:
        """Generate natural language answer with AI insights."""
        if not metrics:
            return "I don't have enough data to answer your query. Please ensure GA4 data is available."
        
        # Format metrics as markdown table
        metrics_table = self._create_metrics_table(metrics)
        
        # Build comprehensive prompt for LLM
        prompt_parts = [
            f"User Query: {query}",
            f"\nCurrent Metrics:\n{metrics_table}",
        ]
        
        # Add historical context if available
        if context:
            prompt_parts.append("\nHistorical Context:")
            for i, ctx in enumerate(context[:3], 1):
                prompt_parts.append(f"{i}. {ctx}")
        
        prompt_parts.extend([
            "\nAnalyze the metrics and provide:",
            "1. A clear answer to the user's query (2-3 sentences)",
            "2. Key trends and insights",
            "3. Actionable recommendations",
            "\nBe concise, data-driven, and business-focused."
        ])
        
        prompt = "\n".join(prompt_parts)
        
        # For now, return a structured response
        # TODO: Integrate with LLM for AI-powered insights
        answer_parts = [
            f"# Analysis of Your GA4 Data\n",
            f"Based on your query: \"{query}\"\n",
            f"## Current Performance\n{metrics_table}\n",
        ]
        
        if context:
            answer_parts.append("## Historical Context")
            for ctx in context[:2]:
                answer_parts.append(f"- {ctx}")
            answer_parts.append("")
        
        answer_parts.extend([
            "## Key Insights",
            "- " + self._generate_key_insight(metrics),
            "\n## Recommendations",
            "- " + self._generate_recommendation(metrics, query)
        ])
        
        return "\n".join(answer_parts)
    
    def _create_metrics_table(self, metrics: Dict[str, Any]) -> str:
        """Create a markdown table from metrics."""
        if not metrics:
            return "No metrics available"
        
        table_lines = [
            "| Metric | Value |",
            "|--------|-------|"
        ]
        
        for name, value in metrics.items():
            formatted_name = name.replace("_", " ").title()
            # Format numeric values with commas
            try:
                num_value = float(value)
                if num_value >= 1:
                    formatted_value = f"{num_value:,.0f}"
                else:
                    formatted_value = f"{num_value:.2%}"
            except:
                formatted_value = str(value)
            
            table_lines.append(f"| {formatted_name} | {formatted_value} |")
        
        return "\n".join(table_lines)
    
    def _generate_key_insight(self, metrics: Dict[str, Any]) -> str:
        """Generate a key insight from metrics."""
        # Simple heuristic-based insight generation
        # In production, this would use the LLM
        
        if not metrics:
            return "Insufficient data to generate insights"
        
        # Find the highest value metric
        numeric_metrics = {}
        for name, value in metrics.items():
            try:
                numeric_metrics[name] = float(value)
            except:
                continue
        
        if not numeric_metrics:
            return "Data shows stable performance across all metrics"
        
        max_metric = max(numeric_metrics.items(), key=lambda x: x[1])
        return f"{max_metric[0].replace('_', ' ').title()} is performing strongly at {max_metric[1]:,.0f}"
    
    def _generate_recommendation(self, metrics: Dict[str, Any], query: str) -> str:
        """Generate an actionable recommendation."""
        # Simple recommendation based on query keywords
        query_lower = query.lower()
        
        if "conversion" in query_lower or "sales" in query_lower:
            return "Consider optimizing your conversion funnel to improve conversion rates"
        elif "traffic" in query_lower or "session" in query_lower:
            return "Focus on traffic acquisition channels that show the highest engagement"
        elif "bounce" in query_lower:
            return "Analyze high-bounce pages and improve content relevance and page load times"
        elif "engagement" in query_lower:
            return "Review user engagement patterns and optimize for longer session durations"
        else:
            return "Continue monitoring these metrics and compare with historical trends"
    
    def _create_charts(self, ga4_data: Dict[str, Any]) -> List[Any]:
        """Create chart configurations from GA4 data."""
        charts = []
        rows = ga4_data.get("rows", [])
        
        if not rows:
            return charts
        
        # Get headers
        dimension_headers = ga4_data.get("dimensionHeaders", [])
        metric_headers = ga4_data.get("metricHeaders", [])
        
        if not dimension_headers or not metric_headers:
            logger.warning("Missing dimension or metric headers in GA4 data")
            return charts
        
        # Determine chart type based on dimension type
        dimension_name = dimension_headers[0].get("name", "").lower()
        metric_name = metric_headers[0].get("name", "Metric")
        
        # Extract data points
        data_points = []
        for row in rows[:30]:  # Limit to 30 data points
            dim_values = row.get("dimensionValues", [])
            metric_values = row.get("metricValues", [])
            
            if dim_values and metric_values:
                try:
                    x_value = dim_values[0].get("value", "")
                    y_value = float(metric_values[0].get("value", 0))
                    
                    data_points.append(
                        ChartDataPoint(x=x_value, y=y_value)
                    )
                except (ValueError, IndexError) as e:
                    logger.warning(f"Skipping invalid data point: {e}")
                    continue
        
        if not data_points:
            logger.warning("No valid data points for chart generation")
            return charts
        
        # Create appropriate chart based on dimension type
        if "date" in dimension_name or "time" in dimension_name:
            # Time-series data → Line chart
            chart = LineChartConfig(
                title=f"{metric_name} Over Time",
                x_label=dimension_headers[0].get("name", "Date"),
                y_label=metric_name,
                data=data_points,
            )
            charts.append(chart)
            
            # Also create area chart for cumulative view
            if len(data_points) > 5:
                area_chart = AreaChartConfig(
                    title=f"{metric_name} Trend",
                    x_label=dimension_headers[0].get("name", "Date"),
                    y_label=metric_name,
                    data=data_points,
                    stacked=False
                )
                charts.append(area_chart)
        
        elif "device" in dimension_name or "source" in dimension_name or "channel" in dimension_name:
            # Categorical data → Bar chart
            bar_chart = BarChartConfig(
                title=f"{metric_name} by {dimension_headers[0].get('name', 'Category')}",
                x_label=dimension_headers[0].get("name", "Category"),
                y_label=metric_name,
                data=data_points,
                horizontal=False
            )
            charts.append(bar_chart)
        
        else:
            # Default to bar chart for other categorical data
            bar_chart = BarChartConfig(
                title=f"{metric_name} Distribution",
                x_label=dimension_headers[0].get("name", "Category"),
                y_label=metric_name,
                data=data_points,
                horizontal=False
            )
            charts.append(bar_chart)
        
        logger.info(f"Created {len(charts)} chart(s) from GA4 data")
        return charts
    
    def _create_metric_cards(self, ga4_data: Dict[str, Any]) -> List[MetricCard]:
        """Create metric cards from GA4 data with enhanced formatting."""
        cards = []
        rows = ga4_data.get("rows", [])
        metric_headers = ga4_data.get("metricHeaders", [])
        
        if not rows or not metric_headers:
            logger.warning("No rows or metric headers for metric card generation")
            return cards
        
        # Create cards for each metric
        for idx, header in enumerate(metric_headers[:6]):  # Support up to 6 cards
            metric_name = header.get("name", f"Metric {idx}")
            
            if rows and idx < len(rows[0].get("metricValues", [])):
                value = rows[0]["metricValues"][idx].get("value", "0")
                
                # Format value based on metric type
                try:
                    num_value = float(value)
                    
                    # Determine format based on metric name
                    if "rate" in metric_name.lower() or "percent" in metric_name.lower():
                        # Percentage metrics
                        formatted_value = f"{num_value:.1f}%"
                    elif "duration" in metric_name.lower() or "time" in metric_name.lower():
                        # Time metrics (assume seconds)
                        if num_value < 60:
                            formatted_value = f"{num_value:.1f}s"
                        else:
                            formatted_value = f"{num_value/60:.1f}m"
                    else:
                        # Count metrics
                        formatted_value = f"{num_value:,.0f}" if num_value >= 1 else f"{num_value:.2f}"
                    
                    # Calculate period-over-period change if previous data available
                    change = None
                    trend = None
                    
                    # Compare with second row if available (simplified period comparison)
                    if len(rows) > 1 and idx < len(rows[1].get("metricValues", [])):
                        prev_value = float(rows[1]["metricValues"][idx].get("value", "0"))
                        if prev_value > 0:
                            pct_change = ((num_value - prev_value) / prev_value) * 100
                            change = f"{pct_change:+.1f}%"
                            trend = "up" if pct_change > 0 else ("down" if pct_change < 0 else "neutral")
                    
                    cards.append(
                        MetricCard(
                            label=metric_name.replace("_", " ").title(),
                            value=formatted_value,
                            change=change,
                            trend=trend,
                        )
                    )
                except (ValueError, ZeroDivisionError) as e:
                    logger.warning(f"Error formatting metric {metric_name}: {e}")
                    # Add card with raw value
                    cards.append(
                        MetricCard(
                            label=metric_name.replace("_", " ").title(),
                            value=str(value),
                            change=None,
                            trend=None,
                        )
                    )
        
        logger.info(f"Created {len(cards)} metric card(s)")
        return cards
    
    def _calculate_confidence(
        self,
        ga4_data: Dict[str, Any],
        context: List[str],
    ) -> float:
        """Calculate report confidence score based on data quality."""
        confidence = 0.5  # Base confidence
        
        # Increase confidence if we have fresh GA4 data
        rows = ga4_data.get("rows", [])
        if rows:
            confidence += 0.2
            # More data points = higher confidence
            if len(rows) >= 7:
                confidence += 0.1
        
        # Increase confidence if we have historical context
        if context:
            confidence += 0.1
            # More context = higher confidence
            if len(context) >= 3:
                confidence += 0.1
        
        return min(1.0, confidence)
    
    def export_to_csv(self, report: ReportResult) -> str:
        """
        Export report data to CSV format.
        
        Implements Task 16: CSV export functionality
        
        Args:
            report: ReportResult to export
            
        Returns:
            CSV-formatted string
            
        Example:
            csv_data = agent.export_to_csv(report)
            with open("report.csv", "w") as f:
                f.write(csv_data)
        """
        import csv
        import io
        
        output = io.StringIO()
        writer = csv.writer(output)
        
        # Write header
        writer.writerow(["Report Export", report.query])
        writer.writerow(["Generated", report.timestamp.isoformat()])
        writer.writerow(["Confidence", f"{report.confidence:.2%}"])
        writer.writerow([])  # Empty row
        
        # Write metric cards
        if report.metrics:
            writer.writerow(["Metric Cards"])
            writer.writerow(["Label", "Value", "Change", "Trend"])
            for metric in report.metrics:
                writer.writerow([
                    metric.label,
                    metric.value,
                    metric.change or "N/A",
                    metric.trend or "N/A"
                ])
            writer.writerow([])  # Empty row
        
        # Write chart data
        for idx, chart in enumerate(report.charts, 1):
            # Extract chart data
            if hasattr(chart, "title") and hasattr(chart, "data"):
                writer.writerow([f"Chart {idx}: {chart.title}"])
                writer.writerow([chart.x_label or "X", chart.y_label or "Y"])
                
                for point in chart.data:
                    writer.writerow([point.x, point.y])
                
                writer.writerow([])  # Empty row
        
        # Write citations
        if report.citations:
            writer.writerow(["Source Citations"])
            writer.writerow(["Metric ID", "Property ID", "Date", "Similarity"])
            for citation in report.citations:
                writer.writerow([
                    citation.metric_id,
                    citation.property_id,
                    citation.metric_date,
                    f"{citation.similarity_score:.3f}"
                ])
        
        return output.getvalue()
    
    def get_report_summary(self, report: ReportResult) -> Dict[str, Any]:
        """
        Get a structured summary of the report for API responses.
        
        Args:
            report: ReportResult to summarize
            
        Returns:
            Dictionary with report summary
        """
        return {
            "query": report.query,
            "timestamp": report.timestamp.isoformat(),
            "confidence": report.confidence,
            "metrics_count": len(report.metrics),
            "charts_count": len(report.charts),
            "citations_count": len(report.citations),
            "tenant_id": report.tenant_id,
            "answer_preview": report.answer[:200] + "..." if len(report.answer) > 200 else report.answer,
        }



